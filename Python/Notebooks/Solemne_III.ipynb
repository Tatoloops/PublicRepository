{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP8QzXFq+KKi4HH1wYD+g8O",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tatoloops/PublicRepository/blob/PyNotebook/Python/Notebooks/Solemne_III.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Solemne III"
      ],
      "metadata": {
        "id": "FOPR0yuDHPVF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Integrantes:  \n",
        "> Tomás Castillo Á  \n",
        "> Carlos Campos  \n",
        "> Sebastián Gonzáles"
      ],
      "metadata": {
        "id": "OqOInImOHTnd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Procesamiento de Datos:"
      ],
      "metadata": {
        "id": "KVQqNbiIHg5-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "el conjunto de datos seleccionado está relacionado con el gasto anual de clientes en diferentes categorías de productos."
      ],
      "metadata": {
        "id": "oAEihnypNZdd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "dataUpload = files.upload()\n",
        "\n",
        "for fn in dataUpload.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(dataUpload[fn])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "qJ3BNQgeKaCd",
        "outputId": "54f96e65-5b6f-4310-85bc-596b1c2d0d4b"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-3c9e45b1-f68a-45f1-8c95-9383cf160314\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-3c9e45b1-f68a-45f1-8c95-9383cf160314\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving WholesaleCustomersData.xlsx to WholesaleCustomersData (1).xlsx\n",
            "User uploaded file \"WholesaleCustomersData (1).xlsx\" with length 23595 bytes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "dataFrame = pd.read_excel(next(iter(dataUpload.keys())))"
      ],
      "metadata": {
        "id": "vRX7QGRsKcjr"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dentro del Dataframe hay información correspondiente a 3 regiones y 2 canales, se procederá a:\n",
        "* Eliminar toda la información del canal 2.\n",
        "* Eliminar toda la información de la región 3.\n",
        "* Eliminar la columna \"Channel\" correspondiente a los canales (ya que toda la información restante pertenecerá al canal 1)  \n",
        "\n",
        "Con esto sólo existirán los gastos anuales correspondientes a las categorías de productos para las regiones 1 y 2 sobre el mismo canal."
      ],
      "metadata": {
        "id": "oGav4AinPt7g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def delete_column(dataframe, column_name):\n",
        "    if column_name in dataframe.columns:\n",
        "        dataframe = dataframe.drop(column_name, axis=1)\n",
        "        print(f\"Column '{column_name}' deleted successfully.\")\n",
        "    else:\n",
        "        print(f\"Column '{column_name}' not found in the DataFrame.\")\n",
        "\n",
        "    return dataframe\n",
        "\n",
        "def delete_rows(dataframe,name,value):\n",
        "    if name in dataframe.columns:\n",
        "        rows_to_delete = dataframe[dataframe[name] == value].index\n",
        "        dataframe = dataframe.drop(index=rows_to_delete)\n",
        "        print(f\"Rows with '{name}' value equal to {value} deleted successfully.\")\n",
        "    else:\n",
        "        print(f\"Column '{name}' not found in the DataFrame.\")\n",
        "\n",
        "    return dataframe\n",
        "\n",
        "dataFrame = delete_rows(dataFrame,\"Channel\",2)\n",
        "dataFrame = delete_rows(dataFrame,\"Region\",3)\n",
        "dataFrame = delete_column(dataFrame,\"Channel\")\n",
        "dataFrame = delete_column(dataFrame,\"Fresh\")\n",
        "dataFrame = delete_column(dataFrame,\"Detergents_Paper\")\n",
        "dataFrame = delete_column(dataFrame,\"Delicassen\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mu9ifdo4KhMU",
        "outputId": "55eda973-99c8-4977-bd19-ab32771ce0ee"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Column 'Channel' not found in the DataFrame.\n",
            "Rows with 'Region' value equal to 3 deleted successfully.\n",
            "Column 'Channel' not found in the DataFrame.\n",
            "Column 'Fresh' deleted successfully.\n",
            "Column 'Detergents_Paper' deleted successfully.\n",
            "Column 'Delicassen' deleted successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Agregamos una columna nueva a nuestro dataFrame llamada \"year\", la cual asignará un año a cada fila de nuestro dataset. Este proceso se realizará por cada región de nuestro estudio (1 y 2)"
      ],
      "metadata": {
        "id": "Zq9pW2a2Zg8B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Assuming your DataFrame is named dataFrame\n",
        "\n",
        "# Create counters for each region\n",
        "yearRegion1 = 1\n",
        "yearRegion2 = 1\n",
        "\n",
        "# Create an empty list to store the year values\n",
        "years = []\n",
        "\n",
        "# Loop through each row in the DataFrame\n",
        "for index, row in dataFrame.iterrows():\n",
        "    # Check the region of the current row\n",
        "    if row['Region'] == 1:\n",
        "        # Assign the year value based on the region counter\n",
        "        years.append(yearRegion1)\n",
        "        # Increment the counter for Region 1\n",
        "        yearRegion1 += 1\n",
        "    elif row['Region'] == 2:\n",
        "        # Assign the year value based on the region counter\n",
        "        years.append(yearRegion2)\n",
        "        # Increment the counter for Region 2\n",
        "        yearRegion2 += 1\n",
        "\n",
        "# Add the \"year\" column to the DataFrame\n",
        "dataFrame['year'] = years\n",
        "\n",
        "# Display the updated DataFrame\n",
        "print(dataFrame)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s19BAqRYZgH0",
        "outputId": "22e751fa-7e08-459f-d968-57d738a12fd2"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Region   Milk  Grocery  Frozen  year\n",
            "196       1   7209     4897   18711     1\n",
            "198       1   2154     6824    3527     2\n",
            "199       1   2280     2112     520     3\n",
            "202       1  11487     9490    5065     4\n",
            "203       1    685     2216     469     5\n",
            "..      ...    ...      ...     ...   ...\n",
            "332       2   3216     1447    2208    24\n",
            "336       2   1511     1330     650    25\n",
            "337       2   1347     2611    8170    26\n",
            "338       2    333     7021   15601    27\n",
            "339       2   1188     5332    9584    28\n",
            "\n",
            "[87 rows x 5 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def delete_column(dataframe, column_name):\n",
        "    if column_name in dataframe.columns:\n",
        "        dataframe = dataframe.drop(column_name, axis=1)\n",
        "        print(f\"Column '{column_name}' deleted successfully.\")\n",
        "    else:\n",
        "        print(f\"Column '{column_name}' not found in the DataFrame.\")\n",
        "\n",
        "    return dataframe\n",
        "\n",
        "# Create two separate DataFrames based on the region\n",
        "dataRegion1 = dataFrame[dataFrame['Region'] == 1]\n",
        "dataRegion2 = dataFrame[dataFrame['Region'] == 2]\n",
        "\n",
        "dataRegion1= delete_column(dataRegion1, \"Region\")\n",
        "dataRegion2= delete_column(dataRegion2, \"Region\")\n",
        "# Display the two DataFrames\n",
        "print(\"Data for Region 1:\")\n",
        "print(dataRegion1)\n",
        "\n",
        "print(\"\\nData for Region 2:\")\n",
        "print(dataRegion2)"
      ],
      "metadata": {
        "id": "hy7LN2t3yKCC",
        "outputId": "b08c9c53-889a-4422-df33-78fff7895f26",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Column 'Region' deleted successfully.\n",
            "Column 'Region' deleted successfully.\n",
            "Data for Region 1:\n",
            "      Milk  Grocery  Frozen  year\n",
            "196   7209     4897   18711     1\n",
            "198   2154     6824    3527     2\n",
            "199   2280     2112     520     3\n",
            "202  11487     9490    5065     4\n",
            "203    685     2216     469     5\n",
            "204    891     5226    1383     6\n",
            "206    780      950     878     7\n",
            "208   3748     5838    1859     8\n",
            "210   1895     1393    1801     9\n",
            "212   1012     2062    1291    10\n",
            "213   6602     6861    1329    11\n",
            "215  10765    15538    1374    12\n",
            "217   1475     2046    2532    13\n",
            "219    367     1390    2306    14\n",
            "220    899     1382    1765    15\n",
            "221   7503    10646      91    16\n",
            "222   1115     2856    7496    17\n",
            "224    659     1499     784    18\n",
            "225   3243     4157     660    19\n",
            "227   2204     1563    2286    20\n",
            "228    577      572     950    21\n",
            "229   2746     2501    6845    22\n",
            "231  10678     3828    1439    23\n",
            "232   1780     3838     638    24\n",
            "233   4984     3316     937    25\n",
            "234   2703     3833    4260    26\n",
            "235   6380     2824    1218    27\n",
            "236    820     3047    2312    28\n",
            "237   3838      593    4634    29\n",
            "238    475      585    1112    30\n",
            "239   2567     3779    5243    31\n",
            "240   3575     7041   11422    32\n",
            "241   1801     2475    2216    33\n",
            "242    659     2914    3752    34\n",
            "243   3576     5119     561    35\n",
            "244   7775    10817    1183    36\n",
            "246   2428     1777    1777    37\n",
            "247    346      489    2077    38\n",
            "248   5279     2406     559    39\n",
            "249   3795     2070    6340    40\n",
            "250   1993     1799    1730    41\n",
            "252   1860     4740    7683    42\n",
            "253   7961    16966     432    43\n",
            "254  17972     4748    4686    44\n",
            "255    489     1495    3242    45\n",
            "256   5008     5249     453    46\n",
            "257   1931     1883    5004    47\n",
            "258   4563     2124    6422    48\n",
            "259   4959     7336    3012    49\n",
            "260   4885     2157     327    50\n",
            "261   1110     1094    6818    51\n",
            "262   1372     1677     982    52\n",
            "263   1115     6684    4324    53\n",
            "265  23527    13699   10155    54\n",
            "267   1222     2576    3975    55\n",
            "269    258     1138    2516    56\n",
            "270   1032      975    5500    57\n",
            "271   5007     1563    1120    58\n",
            "272   8323     6869     529    59\n",
            "\n",
            "Data for Region 2:\n",
            "      Milk  Grocery  Frozen  year\n",
            "294   2013     6550     909     1\n",
            "296   1304     3643    3045     2\n",
            "299    879     2060     264     3\n",
            "307   2374     2842    1149     4\n",
            "308   1020     3007     416     5\n",
            "310   1492     2405   12569     6\n",
            "311   2335     8280    3046     7\n",
            "313    925     2405    4447     8\n",
            "314   1795     7647    1483     9\n",
            "316   1375     2201    2679    10\n",
            "317   3088     6114     978    11\n",
            "318   2713     3558    2121    12\n",
            "320   3696     2280     514    13\n",
            "321   1897     5167    2714    14\n",
            "322    713     3315    3703    15\n",
            "323    944    11593     915    16\n",
            "324   3587     2464    2369    17\n",
            "325  16784    13626   60869    18\n",
            "326   1610     1431    3498    19\n",
            "327    899     1664     414    20\n",
            "328   2209     3389    7849    21\n",
            "329   1486     4583    5127    22\n",
            "330   1786     5109    3570    23\n",
            "332   3216     1447    2208    24\n",
            "336   1511     1330     650    25\n",
            "337   1347     2611    8170    26\n",
            "338    333     7021   15601    27\n",
            "339   1188     5332    9584    28\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para descargar los nuevos conjuntos de datos"
      ],
      "metadata": {
        "id": "gL_J58ctaC_t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataRegion1.to_csv('dataRegion1.csv', index=False)\n",
        "files.download('dataRegion1.csv')\n",
        "\n",
        "dataRegion2.to_csv('dataRegion2.csv', index=False)\n",
        "files.download('dataRegion2.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "h9rAONiGaCeW",
        "outputId": "b619ae7a-a3f9-404c-f0c3-7e8816279af8"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_f297a5a6-848a-41cd-a95f-c91a72e1f719\", \"dataRegion1.csv\", 1055)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_b3a0b8f0-15af-4674-9d73-bdefa7b44e96\", \"dataRegion2.csv\", 512)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Entrenando modelo para futuras predicciones:"
      ],
      "metadata": {
        "id": "gxmrFyqbHrEV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "metadata": {
        "id": "5KM2pWiQNkSp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Entrenamos nuestra máquina con los datos proporcionados."
      ],
      "metadata": {
        "id": "N0SnVfStfckx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# X serán las características de entrada (region, categorías de productos), y será el gasto anual.\n",
        "X = dataRegion1[['Milk', 'Frozen', 'Grocery']]\n",
        "y_columns = ['Milk', 'Frozen', 'Grocery']  # Cambiar 'Milk', 'Frozen', 'Grocery' según tus necesidades\n",
        "\n",
        "# Normalizar los datos\n",
        "scaler = StandardScaler()\n",
        "X_normalized = scaler.fit_transform(X)\n",
        "\n",
        "# Convertir datos a tensores de PyTorch\n",
        "X_tensor = torch.tensor(X_normalized, dtype=torch.float32)\n",
        "y_tensor = torch.tensor(dataRegion1[y_columns].values, dtype=torch.float32)\n",
        "\n",
        "# División de datos (puedes adaptarlo según tus necesidades)\n",
        "X_train_tensor, X_test_tensor, y_train_tensor, y_test_tensor = train_test_split(X_tensor, y_tensor, test_size=0.2, random_state=42)\n",
        "\n",
        "# Definir la arquitectura de la red neuronal\n",
        "class ExpenditurePredictionModel(nn.Module):\n",
        "    def __init__(self, input_size, output_size):\n",
        "        super(ExpenditurePredictionModel, self).__init__()\n",
        "        self.fc = nn.Linear(input_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.fc(x)\n",
        "\n",
        "# Definir la función de pérdida y el optimizador\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "# Entrenamiento del modelo\n",
        "model = ExpenditurePredictionModel(X_train_tensor.shape[1], len(y_columns))\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "epochs = 50\n",
        "for epoch in range(epochs):\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(X_train_tensor)\n",
        "    loss = criterion(outputs, y_train_tensor)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if (epoch + 1) % 100 == 0:\n",
        "        print(f'Epoch [{epoch + 1}/{epochs}], Loss: {loss.item():.4f}')\n",
        "\n",
        "# Evaluación del modelo en datos de prueba\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    y_pred_tensor = model(X_test_tensor)\n",
        "\n",
        "# Predicción para las siguientes 5 filas\n",
        "with torch.no_grad():\n",
        "    future_data = X_test_tensor[:5]\n",
        "    future_predictions = model(future_data)\n",
        "\n",
        "# Convertir los tensores de PyTorch a numpy arrays\n",
        "y_pred_numpy = y_pred_tensor.numpy()\n",
        "future_predictions_numpy = future_predictions.numpy()\n",
        "\n",
        "# Imprimir las predicciones\n",
        "print(\"Predicciones para datos de prueba:\")\n",
        "print(y_pred_numpy)\n",
        "\n",
        "print(\"\\nPredicciones para las siguientes 5 filas:\")\n",
        "print(future_predictions_numpy)\n",
        "\n",
        "# Desnormalizar las predicciones\n",
        "y_pred_denormalized = scaler.inverse_transform(y_pred_numpy)\n",
        "future_predictions_denormalized = scaler.inverse_transform(future_predictions_numpy)\n",
        "\n",
        "# Imprimir las predicciones desnormalizadas\n",
        "print(\"Predicciones desnormalizadas para datos de prueba:\")\n",
        "print(y_pred_denormalized)\n",
        "\n",
        "print(\"\\nPredicciones desnormalizadas para las siguientes 5 filas:\")\n",
        "print(future_predictions_denormalized)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E4bKyP2MsuLz",
        "outputId": "22e81f78-d5b5-4e7c-ff88-a3398a11d27d"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicciones para datos de prueba:\n",
            "[[ 2.73504257e+00  1.35913837e+00  1.07082725e+00]\n",
            " [ 3.03893924e-01  8.79622996e-03 -2.78507262e-01]\n",
            " [ 1.07823044e-01 -3.22485954e-01 -3.45928632e-02]\n",
            " [ 4.10275280e-01 -3.61101091e-01 -5.45934081e-01]\n",
            " [ 5.51346242e-02 -4.37272102e-01  1.21041417e-01]\n",
            " [ 1.12241673e+00  2.22820714e-01  3.02341938e+00]\n",
            " [ 1.10977620e-01 -8.59350860e-01 -9.16533917e-02]\n",
            " [ 6.71165466e-01 -1.12931728e-02 -6.07222654e-02]\n",
            " [ 9.25955296e-01 -1.57405451e-01  1.12632915e-01]\n",
            " [ 4.22695369e-01 -3.40740085e-01 -3.76866013e-01]\n",
            " [ 2.24944949e-03 -8.57240021e-01 -9.80802029e-02]\n",
            " [ 6.26910686e-01  1.01936474e-01  1.26930666e+00]]\n",
            "\n",
            "Predicciones para las siguientes 5 filas:\n",
            "[[ 2.7350426   1.3591384   1.0708272 ]\n",
            " [ 0.30389392  0.00879623 -0.27850726]\n",
            " [ 0.10782304 -0.32248595 -0.03459286]\n",
            " [ 0.41027528 -0.3611011  -0.5459341 ]\n",
            " [ 0.05513462 -0.4372721   0.12104142]]\n",
            "Predicciones desnormalizadas para datos de prueba:\n",
            "[[15526.241    7542.585    7879.7783 ]\n",
            " [ 5165.32     3155.8972   3023.8567 ]\n",
            " [ 4329.7173   2079.7024   3901.6445 ]\n",
            " [ 5618.6895   1954.258    2061.4536 ]\n",
            " [ 4105.173    1706.8109   4461.734  ]\n",
            " [ 8653.65     3851.1719  14906.675  ]\n",
            " [ 4343.161     335.6565   3696.2976 ]\n",
            " [ 6730.5356   3090.6353   3807.611  ]\n",
            " [ 7816.3833   2615.9788   4431.4736 ]\n",
            " [ 5671.6206   2020.4023   2669.888  ]\n",
            " [ 3879.79      342.51367  3673.1692 ]\n",
            " [ 6541.933    3458.4702   8594.057  ]]\n",
            "\n",
            "Predicciones desnormalizadas para las siguientes 5 filas:\n",
            "[[15526.241   7542.585   7879.7783]\n",
            " [ 5165.32    3155.8972  3023.8567]\n",
            " [ 4329.7173  2079.7024  3901.6445]\n",
            " [ 5618.6895  1954.258   2061.4536]\n",
            " [ 4105.173   1706.8109  4461.734 ]]\n"
          ]
        }
      ]
    }
  ]
}